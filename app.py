import streamlit as st
import pandas as pd
import re
import os
import nltk
# Ensure NLTK resources are downloaded
for resource in ['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger']:
    try:
        nltk.data.find(f'tokenizers/{resource}' if resource == 'punkt' else f'corpora/{resource}')
    except LookupError:
        nltk.download(resource)

# Ensure NLTK data directory is set up
nltk_data_dir = os.path.join(os.path.dirname(__file__), "nltk_data")
if nltk_data_dir not in nltk.data.path:
    nltk.data.path.append(nltk_data_dir)

from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag, TreebankWordTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
import joblib

def safe_pos_tag(tokens):
    try:
        return pos_tag(tokens)
    except LookupError as e:
        nltk.download('averaged_perceptron_tagger')
        return pos_tag(tokens)

# âœ… Preprocessing Functions
def get_wordnet_pos(tag):
    if tag.startswith('J'):
        return wordnet.ADJ
    elif tag.startswith('V'):
        return wordnet.VERB
    elif tag.startswith('N'):
        return wordnet.NOUN
    elif tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

def preprocess_text(text):
    # Text cleaning
    text = text.lower()
    text = re.sub(r"n't", ' not', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()

    # Tokenization using Treebank (avoids sent_tokenize)
    tokenizer = TreebankWordTokenizer()
    tokens = tokenizer.tokenize(text)

    # Stopword removal, POS tagging, and lemmatization
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
    pos_tags = safe_pos_tag(tokens)

    def get_wordnet_pos_simple(tag):
        if tag.startswith('J'):
            return 'a'
        elif tag.startswith('V'):
            return 'v'
        elif tag.startswith('N'):
            return 'n'
        elif tag.startswith('R'):
            return 'r'
        else:
            return 'n'

    words = [lemmatizer.lemmatize(word, get_wordnet_pos_simple(tag))
             for word, tag in pos_tags if word not in stop_words]

    return ' '.join(words)

# âœ… Improved Star Rating Function
def get_star_rating(sentiment, confidence):
    if sentiment == 1:  # Positive
        if confidence >= 0.9:
            return "â­â­â­â­â­"
        elif confidence >= 0.75:
            return "â­â­â­â­"
        else:
            return "â­â­â­"
    elif sentiment == 0:  # Neutral
        if confidence >= 0.8:
            return "â­â­â­"
        else:
            return "â­â­"
    else:  # Negative (force low stars)
        if confidence >= 0.9:
            return "â­â­"
        else:
            return "â­"

# âœ… Emoji Feedback Function
def get_emoji_feedback(sentiment, confidence):
    if sentiment == 1:
        if confidence >= 0.9:
            return "ğŸ˜ Extremely Happy"
        elif confidence >= 0.75:
            return "ğŸ˜Š Happy"
        else:
            return "ğŸ™‚ Slightly Positive"
    elif sentiment == 0:
        if confidence >= 0.8:
            return "ğŸ˜ Neutral"
        else:
            return "ğŸ¤” Slightly Neutral"
    else:
        if confidence >= 0.9:
            return "ğŸ˜¡ Very Dissatisfied"
        elif confidence >= 0.75:
            return "ğŸ˜  Angry"
        else:
            return "ğŸ˜ Slightly Negative"

# âœ… Model Training (If Not Already Trained)
model_path = 'sentiment_model_fixed.pkl'
if not os.path.exists(model_path):
    st.info("ğŸ”¨ Training model using your IMDB CSV with Correct Mapping...")

    # âœ… Load your IMDB dataset
    data = pd.read_csv("imdb_reviews.csv")

    # âœ… Correct Sentiment Mapping:
    data['sentiment'] = data['sentiment'].map({0: -1, 1: 1})

    # âœ… Inject Neutral Samples (Optional)
    neutral_data = pd.DataFrame({
        'review': [
            "It was okay",
            "Average movie",
            "Nothing special or bad",
            "It was just fine, not great, not bad",
            "Neutral experience overall",
            "I neither liked nor disliked it"
        ],
        'sentiment': [0, 0, 0, 0, 0, 0]
    })

    data = pd.concat([data, neutral_data], ignore_index=True)

    # âœ… Preprocessing & Training
    data['review'] = data['review'].astype(str).apply(preprocess_text)

    X_train, X_test, y_train, y_test = train_test_split(
        data['review'], data['sentiment'], test_size=0.2, random_state=42
    )

    pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(
            ngram_range=(1, 2),
            max_features=10000,
            min_df=2,
            max_df=0.9,
            sublinear_tf=True,
            stop_words='english'
        )),
        ('clf', LogisticRegression(
            max_iter=1200,
            C=1.5,
            multi_class='multinomial',
            solver='lbfgs',
            class_weight='balanced',
            random_state=42
        ))
    ])

    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)
    print("Model Accuracy Report:\n", classification_report(y_test, y_pred))

    joblib.dump(pipeline, model_path)
    st.success("âœ… Model trained and saved successfully!")
else:
    print("âœ… Model already trained. Loading...")

# âœ… Load Model
model = joblib.load(model_path)

# âœ… Streamlit App UI
st.set_page_config(page_title="3-Class Sentiment Classifier", page_icon="ğŸ’¬", layout="centered")
st.title("ğŸ’¬ Multi-Class Sentiment Classifier (Positive, Neutral, Negative)")
st.subheader("ğŸ” Analyze Sentiment with Star Rating & Emojis")

review = st.text_area("ğŸ“ Enter Your Review:")

if st.button("Predict Sentiment"):
    if review.strip() == "":
        st.warning("âš ï¸ Please enter a review first.")
    else:
        processed_review = preprocess_text(review)
        sentiment = model.predict([processed_review])[0]
        confidence = model.predict_proba([processed_review]).max()

        stars = get_star_rating(sentiment, confidence)
        emoji = get_emoji_feedback(sentiment, confidence)

        sentiment_label = {1: "Positive", 0: "Neutral", -1: "Negative"}.get(sentiment, "Unknown")

        st.success("ğŸ¯ **Prediction Result:**")
        st.markdown(f"**Sentiment:** `{sentiment_label}`")
        st.markdown(f"**Confidence:** `{confidence * 100:.2f}%`")
        st.markdown(f"**Star Rating:** {stars}")
        st.markdown(f"**Emoji Feedback:** {emoji}")

st.markdown("---")
st.caption("ğŸš€ Built with Streamlit, TF-IDF, Logistic Regression & NLP")

